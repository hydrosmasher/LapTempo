{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdfd681a",
   "metadata": {},
   "source": [
    "\n",
    "# COMPETITIVE PACING â€” Model Training & Inference Notebook\n",
    "\n",
    "This notebook:\n",
    "1. Verifies datasets and the leaderboard of best models.\n",
    "2. (Re)builds `best_models_by_stroke.csv` if it's missing.\n",
    "3. Trains the per-stroke, per-target models using the chosen estimator+params.\n",
    "4. Saves models under `/mnt/data/models` and writes a detailed `build_report.json`.\n",
    "5. Shows how to load and run inference with a trained model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991fd9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, ast, re, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# Estimators\n",
    "from sklearn.ensemble import RandomForestRegressor as RandomForest\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "ROOT = Path(\".\")\n",
    "DATASETS_DIR = ROOT / \"datasets\"\n",
    "MODELS_DIR = ROOT / \"models\"\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LEADERBOARD_COMBINED = ROOT / \"best_models_by_stroke.csv\"\n",
    "\n",
    "# Individual leaderboards (already uploaded earlier)\n",
    "LB_FILES = {\n",
    "    \"Freestyle\": ROOT / \"Freestyle_leaderboard.csv\",\n",
    "    \"Backstroke\": ROOT / \"Backstroke_leaderboard.csv\",\n",
    "    \"Breaststroke\": ROOT / \"Breaststroke_leaderboard.csv\",\n",
    "    \"Butterfly\": ROOT / \"Butterfly_leaderboard.csv\",\n",
    "    \"IM\": ROOT / \"IM_leaderboard.csv\",\n",
    "}\n",
    "\n",
    "STROKE_TO_FILE = {\n",
    "    \"Freestyle\": \"freestyle_dataset.csv\",\n",
    "    \"Backstroke\": \"backstroke_dataset.csv\",\n",
    "    \"Breaststroke\": \"breaststroke_dataset.csv\",\n",
    "    \"Butterfly\": \"butterfly_dataset.csv\",\n",
    "    \"IM\": \"im_dataset.csv\",\n",
    "}\n",
    "\n",
    "MODEL_MAP = {\n",
    "    \"RandomForest\": RandomForest,\n",
    "    \"GBR\": GBR,\n",
    "    \"Ridge\": Ridge,\n",
    "    \"Lasso\": Lasso,\n",
    "    \"ElasticNet\": ElasticNet,\n",
    "    \"LinearRegression\": LinearRegression,\n",
    "    \"SVR\": SVR,\n",
    "}\n",
    "\n",
    "SCALER_MODELS = {\"Ridge\",\"Lasso\",\"ElasticNet\",\"LinearRegression\",\"SVR\"}\n",
    "TARGET_PATTERN = re.compile(r\"^frac_\\d+$\", flags=re.IGNORECASE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c717908e",
   "metadata": {},
   "source": [
    "## 1) Verify datasets are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c0e636",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "available = []\n",
    "if DATASETS_DIR.exists():\n",
    "    for f in DATASETS_DIR.glob(\"*.csv\"):\n",
    "        available.append(f.name)\n",
    "\n",
    "print(\"Found dataset files:\", available)\n",
    "missing = [v for v in STROKE_TO_FILE.values() if v not in available]\n",
    "if missing:\n",
    "    print(\"[WARN] Missing expected dataset files:\", missing)\n",
    "else:\n",
    "    print(\"[OK] All expected datasets present.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c00be9",
   "metadata": {},
   "source": [
    "## 2) Build/Load combined leaderboard of best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a5f69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pick_best(df):\n",
    "    # Expect columns: target, model, bestparams, r2, mse (case-insensitive handled below)\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "    # Sort by r2 desc, mse asc\n",
    "    df_sorted = df.sort_values(by=[\"r2\", \"mse\"], ascending=[False, True])\n",
    "    best = df_sorted.groupby(\"target\", as_index=False).first()\n",
    "    return best\n",
    "\n",
    "if not LEADERBOARD_COMBINED.exists():\n",
    "    print(\"[INFO] Combined leaderboard not found. Recomputing from individual files...\")\n",
    "    frames = []\n",
    "    for stroke, path in LB_FILES.items():\n",
    "        if path.exists():\n",
    "            df = pd.read_csv(path)\n",
    "            best = pick_best(df)\n",
    "            best.insert(0, \"stroke\", stroke)\n",
    "            frames.append(best)\n",
    "        else:\n",
    "            print(f\"[WARN] Missing leaderboard for {stroke}: {path}\")\n",
    "    if not frames:\n",
    "        raise FileNotFoundError(\"No leaderboards found to build combined leaderboard.\")\n",
    "    combined = pd.concat(frames, ignore_index=True)\n",
    "    combined.rename(columns={\"bestparams\":\"bestparams\",\"model\":\"model\",\"target\":\"target\",\"r2\":\"r2\",\"mse\":\"mse\"}, inplace=True)\n",
    "    combined.to_csv(LEADERBOARD_COMBINED, index=False)\n",
    "    print(\"[OK] Wrote combined leaderboard to\", LEADERBOARD_COMBINED)\n",
    "else:\n",
    "    combined = pd.read_csv(LEADERBOARD_COMBINED)\n",
    "    print(\"[OK] Loaded existing combined leaderboard from\", LEADERBOARD_COMBINED)\n",
    "\n",
    "display(combined.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f377b7eb",
   "metadata": {},
   "source": [
    "## 3) Helpers for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96495104",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_bestparams(s: str) -> dict:\n",
    "    if pd.isna(s) or not str(s).strip():\n",
    "        return {}\n",
    "    try:\n",
    "        d = ast.literal_eval(s)\n",
    "    except Exception:\n",
    "        # naive fallback\n",
    "        d = {}\n",
    "        s2 = str(s).strip().strip(\"{}\")\n",
    "        for part in s2.split(\",\"):\n",
    "            if not part.strip(): continue\n",
    "            if \":\" in part:\n",
    "                k, v = part.split(\":\", 1)\n",
    "                d[k.strip().strip(\"'\").strip('\"')] = ast.literal_eval(v.strip())\n",
    "    return d\n",
    "\n",
    "def make_pipeline(model_name: str, params: dict, feature_cols):\n",
    "    model_cls = MODEL_MAP[model_name]\n",
    "    model = model_cls()\n",
    "\n",
    "    # Normalize params to 'model__' namespaced keys\n",
    "    p2 = {}\n",
    "    for k, v in params.items():\n",
    "        if k.startswith(\"model__\"):\n",
    "            p2[k] = v\n",
    "        else:\n",
    "            p2[f\"model__{k}\"] = v\n",
    "\n",
    "    pre = ColumnTransformer(\n",
    "        [(\"num\", StandardScaler() if model_name in SCALER_MODELS else \"passthrough\", list(feature_cols))],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([(\"pre\", pre), (\"model\", model)])\n",
    "    if p2:\n",
    "        pipe.set_params(**p2)\n",
    "    return pipe\n",
    "\n",
    "def kfold_metrics(model, X, y, n_splits=5):\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        r2 = cross_val_score(model, X, y, cv=cv, scoring=\"r2\")\n",
    "        neg_mse = cross_val_score(model, X, y, cv=cv, scoring=\"neg_mean_squared_error\")\n",
    "    return {\n",
    "        \"r2_mean\": float(np.mean(r2)), \"r2_std\": float(np.std(r2)),\n",
    "        \"mse_mean\": float(np.mean(-neg_mse)), \"mse_std\": float(np.std(-neg_mse))\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985457fc",
   "metadata": {},
   "source": [
    "## 4) Train and save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fcd9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joblib\n",
    "\n",
    "build_report = []\n",
    "\n",
    "for stroke, sub in combined.groupby(\"stroke\"):\n",
    "    ds_name = STROKE_TO_FILE.get(stroke)\n",
    "    ds_path = DATASETS_DIR / ds_name if ds_name else None\n",
    "\n",
    "    if not ds_path or not ds_path.exists():\n",
    "        print(f\"[WARN] Dataset for {stroke} not found at {ds_path}. Skipping this stroke.\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(ds_path)\n",
    "\n",
    "    target_cols = [c for c in df.columns if TARGET_PATTERN.match(str(c))]\n",
    "    # features: numeric that are not targets\n",
    "    feature_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c not in target_cols]\n",
    "    if not feature_cols:\n",
    "        feature_cols = [c for c in df.columns if c not in target_cols]\n",
    "\n",
    "    print(f\"\\n[INFO] {stroke}: Using {len(feature_cols)} features and {len(target_cols)} targets: {target_cols}\")\n",
    "\n",
    "    stroke_dir = MODELS_DIR / stroke\n",
    "    stroke_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for _, row in sub.iterrows():\n",
    "        target = row[\"target\"]\n",
    "        model_name = row[\"model\"]\n",
    "        params = parse_bestparams(row[\"bestparams\"])\n",
    "\n",
    "        if target not in df.columns:\n",
    "            print(f\"[WARN] Target '{target}' missing in dataset for {stroke}; skipping.\")\n",
    "            continue\n",
    "\n",
    "        X = df[feature_cols].copy()\n",
    "        y = df[target].values\n",
    "\n",
    "        pipe = make_pipeline(model_name, params, feature_cols)\n",
    "\n",
    "        # CV metrics on training data (for record)\n",
    "        try:\n",
    "            cvm = kfold_metrics(pipe, X, y, n_splits=5)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] CV failed for {stroke}/{target} with {model_name}: {e}\")\n",
    "            cvm = None\n",
    "\n",
    "        pipe.fit(X, y)\n",
    "\n",
    "        model_path = stroke_dir / f\"{target}_{model_name}.joblib\"\n",
    "        joblib.dump(pipe, model_path)\n",
    "\n",
    "        meta = {\n",
    "            \"stroke\": stroke,\n",
    "            \"target\": target,\n",
    "            \"model\": model_name,\n",
    "            \"bestparams\": params,\n",
    "            \"features\": feature_cols,\n",
    "            \"dataset\": str(ds_path),\n",
    "            \"model_path\": str(model_path),\n",
    "            \"cv_metrics\": cvm,\n",
    "        }\n",
    "        build_report.append(meta)\n",
    "        print(f\"[OK] Saved {stroke}/{target} -> {model_path.name}\")\n",
    "\n",
    "    with open(stroke_dir / \"index.json\", \"w\") as f:\n",
    "        json.dump([m for m in build_report if m[\"stroke\"] == stroke], f, indent=2)\n",
    "\n",
    "# global report\n",
    "with open(MODELS_DIR / \"build_report.json\", \"w\") as f:\n",
    "    json.dump(build_report, f, indent=2)\n",
    "\n",
    "print(\"\\n[DONE] Training complete. Summary:\")\n",
    "pd.DataFrame(build_report)[[\"stroke\",\"target\",\"model\",\"model_path\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd21b2e",
   "metadata": {},
   "source": [
    "## 5) Build report summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824e9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "report_df = pd.DataFrame(build_report)\n",
    "display(report_df.head(20))\n",
    "\n",
    "report_csv = MODELS_DIR / \"build_report.csv\"\n",
    "report_df.to_csv(report_csv, index=False)\n",
    "print(\"Saved:\", report_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef44c5c",
   "metadata": {},
   "source": [
    "## 6) Load a trained model and predict (registry-like helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926210cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json, joblib\n",
    "\n",
    "def list_trained(stroke: str):\n",
    "    idx_path = MODELS_DIR / stroke / \"index.json\"\n",
    "    if not idx_path.exists():\n",
    "        return []\n",
    "    with open(idx_path, \"r\") as f:\n",
    "        meta = json.load(f)\n",
    "    return meta\n",
    "\n",
    "def load_model(stroke: str, target: str):\n",
    "    metas = list_trained(stroke)\n",
    "    candidates = [m for m in metas if m[\"target\"] == target]\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"No trained model for {stroke}/{target}\")\n",
    "    m = candidates[0]\n",
    "    path = Path(m[\"model_path\"])\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Model file missing at {path}\")\n",
    "    return joblib.load(path), m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25237c24",
   "metadata": {},
   "source": [
    "### Inference demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca77f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pick a stroke & target that were trained (adjust as needed)\n",
    "example_stroke = \"Freestyle\"\n",
    "example_target = \"frac_1\"\n",
    "\n",
    "# Load dataset to get feature columns\n",
    "ds_path = DATASETS_DIR / STROKE_TO_FILE[example_stroke]\n",
    "df = pd.read_csv(ds_path)\n",
    "\n",
    "target_cols = [c for c in df.columns if TARGET_PATTERN.match(str(c))]\n",
    "feature_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c not in target_cols]\n",
    "if not feature_cols:\n",
    "    feature_cols = [c for c in df.columns if c not in target_cols]\n",
    "\n",
    "pipe, meta = load_model(example_stroke, example_target)\n",
    "\n",
    "# Use a few samples from the dataset for a quick check\n",
    "X_sample = df[feature_cols].head(5)\n",
    "y_pred = pipe.predict(X_sample)\n",
    "\n",
    "print(\"Loaded model:\", meta[\"model\"], \"for\", example_stroke, example_target)\n",
    "print(\"Predictions:\", y_pred)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
