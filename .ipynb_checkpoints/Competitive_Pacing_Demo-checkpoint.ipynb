{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ab448f",
   "metadata": {},
   "source": [
    "\n",
    "# üèä‚Äç‚ôÇÔ∏è Swim‚ÄëForge: Competitive Pacing (Demo Notebook)\n",
    "\n",
    "This notebook runs the **competitive pacing** pipeline with **encoding‚Äësafe CSV loading**, split normalization, and pacing analytics.\n",
    "\n",
    "**What you need:**  \n",
    "- Place your stroke CSVs inside a `datasets/` folder next to this notebook (or update the path in the cell below).  \n",
    "- Expected filenames (customize if needed):  \n",
    "  - `backstroke_dataset.csv`  \n",
    "  - `breaststroke_dataset.csv`  \n",
    "  - `butterfly_dataset.csv`  \n",
    "  - `freestyle_dataset.csv`  \n",
    "  - `im_dataset.csv`\n",
    "\n",
    "**Outputs:**  \n",
    "- Analysis CSVs are written to an `outputs/` folder (customizable).  \n",
    "- You‚Äôll also see a quick preview in the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d773a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Make sure Python can import competitive_pacing.py saved by ChatGPT\n",
    "module_path = Path('/mnt/data')\n",
    "if str(module_path) not in sys.path:\n",
    "    sys.path.append(str(module_path))\n",
    "\n",
    "# Quick check\n",
    "print('Module search path includes:', module_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebc89f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from competitive_pacing import run_pacing_pipeline\n",
    "print('Imported run_pacing_pipeline successfully.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0c478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# üëâ Update these if your folders differ\n",
    "DATASETS_DIR = Path('datasets')   # change to your datasets folder\n",
    "OUTPUT_DIR = Path('outputs')      # where CSVs will be saved\n",
    "STROKES = ['Backstroke', 'Breaststroke', 'Butterfly', 'Freestyle', 'IM']  # subset or None for all\n",
    "\n",
    "print('Datasets dir:', DATASETS_DIR.resolve())\n",
    "print('Output dir   :', OUTPUT_DIR.resolve())\n",
    "print('Strokes      :', STROKES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d02b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = run_pacing_pipeline(\n",
    "    datasets_dir=DATASETS_DIR,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    strokes=STROKES,   # or None to process all defaults\n",
    "    save_csv=True\n",
    ")\n",
    "\n",
    "# Preview: show a few rows per stroke\n",
    "import pandas as pd\n",
    "for stroke, df in results.items():\n",
    "    print(f\"\\n--- {stroke} ---\")\n",
    "    cols = [c for c in [\"athlete_id\",\"event\",\"date\",\"split_no\",\"split_time_sec\",\"avg_split_sec\",\"delta_vs_avg_sec\",\"pct_deviation\",\"pacing_type\"] if c in df.columns]\n",
    "    display(df[cols].head(10) if cols else df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f428b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "sug_files = list(OUTPUT_DIR.glob('*_pacing_suggestions.csv'))\n",
    "if not sug_files:\n",
    "    print('No suggestion CSVs found yet (may depend on datasets having event/date columns).')\n",
    "else:\n",
    "    for f in sug_files:\n",
    "        print(f\"\\nSuggestions: {f.name}\")\n",
    "        display(pd.read_csv(f).head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
